{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a1222f2",
   "metadata": {},
   "source": [
    "# Assignment 6 - DUAl identity\n",
    "\n",
    "<div style=\"text-align: right\">\n",
    "Uday Kiran Dasari, Nidhi Nitin Kulkarni, Aniket Patole, Jilson Correia</div>\n",
    "\n",
    "\n",
    "This notebook contains the script to generate our movie - DuaL Identity in English and Telugu. The story is inspired by the Tamil Movie \"Robot\" and the writer had a run with her imagination. Set in Boston, it is about a smart scientist caught in the midst of the chaos he created. All the images used have been captured on iPhone 12 and Pixel 7. \n",
    "\n",
    " \n",
    "\n",
    "Create cartoon like images of captured images using the Function cartoonize and cartoonizebw(Processed images are stored in folder Cartoon)\n",
    "Add subtitles to the images using the function addcaptions and then add border using a function\n",
    "Create strips of images using the function h_strip(processed images are stored in the folder HStrip for Horizontal Strip and VStrip for vertical strip)\n",
    "Generate pdf using the strips for english. (Final pdf is stored as DuaL Identity and DuaL_Identity_Telugu)\n",
    "All the funtions except cartoonize and cartoonizebw is called again for the telugu version with the required arguments.\n",
    "Raw folder has the 60 images used to tell the story and the subtitle file - D2.csv and Font.ttf is the font used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314eaf3e",
   "metadata": {},
   "source": [
    "### Cartoonize the image in Colour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bec2a84",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Colour\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "from IPython.display import display\n",
    "\n",
    "def imgcompress(path_in, path_out, k):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    scaled = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # get the resized image output by imwrite() function of openCV library\n",
    "    cv2.imwrite(path_out, scaled)\n",
    "    \n",
    "    # display result\n",
    "    imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(imgc_pil))\n",
    "    \n",
    "def cartoonize(path_in, path_out, k,line,blur):\n",
    "    \n",
    "    imgcompress(path_in, path_out, k)\n",
    "    imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    bigedges_pil = cv2.cvtColor(bigedges, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "\n",
    "    cartoon = cv2.bitwise_and(imgc, imgc, mask=bigedges)\n",
    "    #cartoon_pil = cv2.cvtColor(cartoon, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    cv2.imwrite(path_out, cartoon)\n",
    " #   display(Image.fromarray(cv2.cvtColor(cartoon, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447bee90",
   "metadata": {},
   "source": [
    "### Cartoonize the image in B&W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b070ed84",
   "metadata": {},
   "outputs": [],
   "source": [
    "##B&W\n",
    "\n",
    "from PIL import Image\n",
    "import cv2 \n",
    "from IPython.display import display\n",
    "\n",
    "def imgcompress(path_in, path_out, k):\n",
    "    img = cv2.imread(path_in, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "    # set the ratio of resized image\n",
    "    width = int((img.shape[1])/k)\n",
    "    height = int((img.shape[0])/k)\n",
    "\n",
    "    # resize the image by resize() function of openCV library\n",
    "    scaled = cv2.resize(img, (width, height), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # get the resized image output by imwrite() function of openCV library\n",
    "    cv2.imwrite(path_out, scaled)\n",
    "    \n",
    "    # display result\n",
    "    imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    #display(Image.fromarray(imgc_pil))\n",
    "    \n",
    "def cartoonizebw(path_in, path_out, k,line,blur):\n",
    "    \n",
    "    imgcompress(path_in, path_out, k)\n",
    "    imgc = cv2.imread(path_out, cv2.IMREAD_UNCHANGED)\n",
    "    imgc_pil = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY) # Converting BGR to RGB\n",
    "\n",
    "    line_size = line\n",
    "    blur_value = blur\n",
    "    gray = cv2.cvtColor(imgc, cv2.COLOR_BGR2GRAY)\n",
    "    gray_blur = cv2.medianBlur(gray, blur_value)\n",
    "    bigedges = cv2.adaptiveThreshold(gray_blur, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, line_size, blur_value)\n",
    "    bigedges_pil = cv2.cvtColor(bigedges, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "\n",
    "    cartoon = cv2.bitwise_and(imgc_pil, imgc_pil, mask=bigedges)\n",
    "    #cartoon_pil = cv2.cvtColor(cartoon, cv2.COLOR_BGR2RGB) # Converting BGR to RGB\n",
    "    cv2.imwrite(path_out, cartoon)\n",
    "    #display(Image.fromarray(cv2.cvtColor(cartoon, cv2.COLOR_BGR2RGB)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "522722e9",
   "metadata": {},
   "source": [
    "### Adding Borders and saving to a folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc51004a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Addborder(path_in, path_out):\n",
    "    from PIL import Image as pili, ImageOps as piliops\n",
    "    piliops.expand(pili.open(path_in), border=(35,35),fill='white').save(path_out)\n",
    "#    from IPython.display import Image\n",
    "#    Image(filename=path_out, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fb67e73",
   "metadata": {},
   "source": [
    "### Adding Captions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b24fb11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Addcaptions(path_in,path_out,dpath,i):\n",
    "    import pandas as pd\n",
    "    data = pd.read_csv(dpath)\n",
    "    from PIL import Image as pili, ImageDraw as pild, ImageFont as pilf \n",
    "\n",
    "    caption = data.values[i][0]\n",
    "    #print(caption)\n",
    "\n",
    "    TINT_COLOR = (0, 0, 0)  # Black\n",
    "    TRANSPARENCY = .25  # Degree of transparency, 0-100%\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "\n",
    "\n",
    "    from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "    img = pili.open(path_in).convert('RGBA')\n",
    "\n",
    "    overlay = pili.new('RGBA', img.size, TINT_COLOR+(0,))\n",
    "    draw = pild.Draw(overlay)\n",
    "    font = pilf.truetype(\"NotoSans-Bold.ttf\", 21)\n",
    "    #x, y = (img.width - 510, img.height-100)\n",
    "    text = caption\n",
    "    w, h = font.getsize(text)\n",
    "    num_lines = len(text.split('\\n'))\n",
    "    #print(num_lines, w, h)\n",
    "    x, y = 10, img.height - (num_lines-0.1*num_lines)*h\n",
    "    #draw.rectangle((x, y, x + w, y + h), fill='black')\n",
    "    #draw.rectangle((x, y, x + w, y + 4*h), fill=TINT_COLOR+(OPACITY,))\n",
    "    draw.rectangle((x, y, x + img.width - 100, y + (num_lines-0.1*num_lines)*h), fill=TINT_COLOR+(150,))\n",
    "    draw.text((x, y), text, fill=(255, 255, 255), font=font)\n",
    "\n",
    "    # Alpha composite these two images together to obtain the desired result.\n",
    "    img = pili.alpha_composite(img, overlay)\n",
    "    img = img.convert(\"RGB\") # Remove alpha for saving in jpg format.\n",
    "\n",
    "    img.save(path_out)\n",
    "#    from IPython.display import Image\n",
    "#    Image(filename=path_out, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cafd918",
   "metadata": {},
   "source": [
    "### Adding language fonts to the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df55f670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Addcaptionsl(path_in,path_out,dpath,i):\n",
    "    from PIL import Image as pili, ImageDraw as pild, ImageFont as pilf \n",
    "    import pandas as pd\n",
    "    dialogs = pd.read_csv(dpath)\n",
    "\n",
    "    caption = dialogs.values[i][1]\n",
    "\n",
    "    TINT_COLOR = (0, 0, 0)  # Black\n",
    "    TRANSPARENCY = .25  # Degree of transparency, 0-100%\n",
    "    OPACITY = int(255 * TRANSPARENCY)\n",
    "\n",
    "    from PIL import Image, ImageFont, ImageDraw\n",
    "\n",
    "    img = pili.open(path_in).convert('RGBA')\n",
    "\n",
    "    overlay = pili.new('RGBA', img.size, TINT_COLOR+(0,))\n",
    "    draw = pild.Draw(overlay)\n",
    "    font = pilf.truetype(\"./NotoSans-Bold.ttf\", 21)\n",
    "\n",
    "    #x, y = (img.width - 510, img.height-100)\n",
    "    text = caption\n",
    "    #print(caption)\n",
    "    w, h = font.getsize(text)\n",
    "    num_lines = len(text.split('\\n'))\n",
    "    #sprint(num_lines, w, h)\n",
    "    x, y = 0, img.height - (num_lines-0.1*num_lines)*h\n",
    "    #draw.rectangle((x, y, x + w, y + h), fill='black')\n",
    "    #draw.rectangle((x, y, x + w, y + 4*h), fill=TINT_COLOR+(OPACITY,))\n",
    "    draw.rectangle((x, y, x + img.width - 200, y + (num_lines-0.1*num_lines)*h), fill=TINT_COLOR+(150,))\n",
    "    draw.text((x, y), text, fill=(255, 255, 255), font=font)\n",
    "\n",
    "\n",
    "    # Alpha composite these two images together to obtain the desired result.\n",
    "    img = pili.alpha_composite(img, overlay)\n",
    "    img = img.convert(\"RGB\") # Remove alpha for saving in jpg format.\n",
    "\n",
    "    img.save(path_out)\n",
    "#    from IPython.display import Image\n",
    "#    Image(filename=path_out, width=400)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8633401b",
   "metadata": {},
   "source": [
    "### Horizontal Strip and Vertical Strip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5147c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hstrip(path_in,path_out,i):\n",
    "    import numpy as np\n",
    "    import PIL\n",
    "    from PIL import Image \n",
    "\n",
    "    list_im = [path_in+f'{i}CCaB.jpg',path_in+f'{i+1}CCaB.jpg',path_in+f'{i+2}CCaB.jpg']\n",
    "    imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "\n",
    "    # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "    # save that beautiful picture\n",
    "    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "    imgs_comb.save( path_out+f'h{i}.jpg')\n",
    "    from IPython.display import Image\n",
    "    Image(filename=path_out+f'h{i}.jpg', width=400)\n",
    "\n",
    "def vstrip(path_in,path_out,i):\n",
    "    import numpy as np\n",
    "    import PIL\n",
    "    from PIL import Image \n",
    "\n",
    "    list_im = [path_in+f'h{i}.jpg',path_in+f'h{i+3}.jpg',path_in+f'h{i+6}.jpg',path_in+f'h{i+9}.jpg']\n",
    "    imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "\n",
    "    # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.vstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "    # save that beautiful picture\n",
    "    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "    imgs_comb.save( path_out+f'v{i}.jpg' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60a9bc60",
   "metadata": {},
   "source": [
    "### Horizontal Strip and Vertical Strip for Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9763a1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lhstrip(path_in,path_out,i):\n",
    "    import numpy as np\n",
    "    import PIL\n",
    "    from PIL import Image \n",
    "\n",
    "    list_im = [path_in+f'{i}CCaLB.jpg',path_in+f'{i+1}CCaLB.jpg',path_in+f'{i+2}CCaLB.jpg']\n",
    "    imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "\n",
    "    # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.hstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "    # save that beautiful picture\n",
    "    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "    imgs_comb.save( path_out+f'lh{i}.jpg')\n",
    "    from IPython.display import Image\n",
    "    Image(filename=path_out+f'lh{i}.jpg', width=400)\n",
    "\n",
    "def lvstrip(path_in,path_out,i):\n",
    "    import numpy as np\n",
    "    import PIL\n",
    "    from PIL import Image \n",
    "\n",
    "    list_im = [path_in+f'lh{i}.jpg',path_in+f'lh{i+3}.jpg',path_in+f'lh{i+6}.jpg',path_in+f'lh{i+9}.jpg']\n",
    "    imgs    = [ PIL.Image.open(i) for i in list_im ]\n",
    "\n",
    "    # pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\n",
    "    min_shape = sorted( [(np.sum(i.size), i.size ) for i in imgs])[0][1]\n",
    "    imgs_comb = np.vstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n",
    "\n",
    "    # save that beautiful picture\n",
    "    imgs_comb = PIL.Image.fromarray( imgs_comb)\n",
    "    imgs_comb.save( path_out+f'lv{i}.jpg' ) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0319f2",
   "metadata": {},
   "source": [
    "# Reading the images from Raw folder -> Cartoonize (Cartoon Folder) -> Add Captions (Captions) -> Add Border (Border) -> Horizontal Strip (Hstrip) -> Vertical Strip (Vstrip) -> Convert to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f91dc297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image as pili , ImageDraw as pild, ImageFont as pilf\n",
    "\n",
    " \n",
    "\n",
    "# Open an image or create a new one\n",
    "image = pili.open(\"./RAW/black.jpg\")\n",
    "\n",
    " \n",
    "\n",
    "# Initialize a drawing context directly from the image\n",
    "draw = pild.Draw(image)\n",
    "\n",
    " \n",
    "\n",
    "# Specify the font and size\n",
    "font = pilf.truetype(\"NotoSans-Bold.ttf\", size=60)  # Replace with the path to your font file\n",
    "\n",
    " \n",
    "\n",
    "# # Specify the text content and color\n",
    "# # text = '''\n",
    "# # The following film is a work of fiction created for entertainment purposes. \n",
    "# # Any resemblance to real persons, living or dead, is purely coincidental. \n",
    "# # The events, characters, and organizations depicted in this movie are products of the writers' imaginations \n",
    "# # and are not intended to represent or depict real individuals, events, or entities. \n",
    "# # Any unauthorized copying, reproduction, distribution, or public performance is strictly prohibited \n",
    "# # and may be subject to legal action (we'll definitely try) .\n",
    "# # Thank you for watching DuaL Identity. \n",
    "# # We hope you enjoy the show.'''\n",
    "\n",
    " \n",
    "\n",
    "# text_color = (255, 255, 255)  # RGB color\n",
    "\n",
    " \n",
    "\n",
    "# # Draw the text on the image\n",
    "# draw.text((300,500), text, fill=text_color, font=font)\n",
    "\n",
    " \n",
    "\n",
    "# # Save or display the image\n",
    "# image.save(\"./RAW/0.jpg\")  # Save the modified image to a file\n",
    "# #image.show()  # Display the image using the default image viewer\n",
    " \n",
    " \n",
    " \n",
    " \n",
    "image = pili.open(\"./RAW/black.jpg\")\n",
    "draw = pild.Draw(image)\n",
    "text1 = '3 Months Earlier'\n",
    "font = pilf.truetype(\"GFFont.ttf\", size=400)\n",
    "text_color = (255, 255, 255)\n",
    "draw.text((1500,800), text1, fill=text_color, font=font)\n",
    "image.save(\"./RAW/3.jpg\")  # Save the modified image to a file\n",
    "#image.show()\n",
    " \n",
    " \n",
    "image = pili.open(\"./RAW/black.jpg\")\n",
    "draw = pild.Draw(image)\n",
    "text2 = '6 Months Later'\n",
    "font = pilf.truetype(\"GFFont.ttf\", size=400)\n",
    "text_color = (255, 255, 255)\n",
    "draw.text((1500,800), text2, fill=text_color, font=font)\n",
    "image.save(\"./RAW/48.jpg\")  # Save the modified image to a file\n",
    "#image.show()\n",
    " \n",
    " \n",
    "image = pili.open(\"./RAW/black.jpg\")\n",
    "draw = pild.Draw(image)\n",
    "text3 = 'The End?'\n",
    "font = pilf.truetype(\"GFFont.ttf\", size=600)\n",
    "text_color = (255, 255, 255)\n",
    "draw.text((1500,800), text3, fill=text_color, font=font)\n",
    "image.save(\"./RAW/57.jpg\")  # Save the modified image to a file\n",
    "#image.show()\n",
    " \n",
    " \n",
    "\n",
    "# image = pili.open(\"./RAW/black.jpg\")\n",
    "# text_color = (255, 255, 255)  \n",
    "# draw = pild.Draw(image)\n",
    "# text4 = '''DuaL Identity\n",
    "\n",
    "# CAST\n",
    "# - Dr. Roy: Jilson\n",
    "# - Dr. Aniket: Aniket\n",
    "# - Special Agent Nidhi: Nidhi\n",
    "# - Special Agent Uday: Uday\n",
    "# - DuaL: Dua Lipa\n",
    "\n",
    "# CREW\n",
    "\n",
    "# Screenplay : Nidhi Kulkarni\n",
    "# Cinematography : Uday\n",
    "# Edited by: Everyone on Monster's\n",
    "# Costume Designer: Individual Wardrobe\n",
    "# Makeup and Hair Stylist: Born that way\n",
    "# Visual Effects Supervisor: Dino'''\n",
    "# font = pilf.truetype(\"GFFont.ttf\", size=100)\n",
    "# draw.text((700,250), text4, fill=text_color, font=font)\n",
    "# image.save(\"./RAW/58.jpg\")  # Save the modified image to a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5d70c5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i:0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@11.994] global loadsave.cpp:248 findDecoder imread_('G:/NEU/DSEM 6105/Assignments/Assignment 6/Raw/0.jpg'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mi:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m4\u001b[39m,\u001b[38;5;241m40\u001b[39m)): cartoonizebw(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Raw/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mC.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m7\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m: cartoonize(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Raw/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mC.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;241m5\u001b[39m,\u001b[38;5;241m11\u001b[39m,\u001b[38;5;241m7\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#Adding Captions\u001b[39;00m\n\u001b[1;32m      7\u001b[0m Addcaptions(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mC.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Captions/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCa.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/D2.csv\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n",
      "Cell \u001b[0;32mIn[1], line 27\u001b[0m, in \u001b[0;36mcartoonize\u001b[0;34m(path_in, path_out, k, line, blur)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcartoonize\u001b[39m(path_in, path_out, k,line,blur):\n\u001b[0;32m---> 27\u001b[0m     imgcompress(path_in, path_out, k)\n\u001b[1;32m     28\u001b[0m     imgc \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path_out, cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\n\u001b[1;32m     29\u001b[0m     imgc_pil \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(imgc, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2RGB) \u001b[38;5;66;03m# Converting BGR to RGB\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[2], line 11\u001b[0m, in \u001b[0;36mimgcompress\u001b[0;34m(path_in, path_out, k)\u001b[0m\n\u001b[1;32m      8\u001b[0m img \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(path_in, cv2\u001b[38;5;241m.\u001b[39mIMREAD_UNCHANGED)\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# set the ratio of resized image\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\u001b[38;5;241m/\u001b[39mk)\n\u001b[1;32m     12\u001b[0m height \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m((img\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;241m/\u001b[39mk)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# resize the image by resize() function of openCV library\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "for i in range(0,60):\n",
    "    #Cartoonize the image\n",
    "    print(f'i:{i}')\n",
    "    if (i in range(4,40)): cartoonizebw(f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Raw/{i}.jpg',f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/{i}C.jpg',5,11,7)\n",
    "    else: cartoonize(f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Raw/{i}.jpg',f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/{i}C.jpg',5,11,7)\n",
    "    #Adding Captions\n",
    "    Addcaptions(f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/{i}C.jpg',f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Captions/{i}CCa.jpg','G:/NEU/DSEM 6105/Assignments/Assignment 6/D2.csv',i)\n",
    "    #Adding Border\n",
    "    Addborder(f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Captions/{i}CCa.jpg',f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Border/{i}CCaB.jpg')\n",
    "    #Adding Language Captions\n",
    "    Addcaptionsl(f'G:/NEU/DSEM 6105/Assignments/Assignment 6/Cartoon/{i}C.jpg',f'G:/NEU/DSEM 6105/Assignments/Assignment 6/LCaptions/{i}CCaL.jpg','G:/NEU/DSEM 6105/Assignments/Assignment 6/D2.csv',i)\n",
    "    #Adding Border to Language Pics\n",
    "    Addborder(f'G:/NEU/DSEM 6105/Assignments/Assignment 6/LCaptions/{i}CCaL.jpg',f'G:/NEU/DSEM 6105/Assignments/Assignment 6/LBorder/{i}CCaLB.jpg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51db7f6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'G:/NEU/DSEM 6105/Assignments/Assignment 6/Border/0CCaB.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m60\u001b[39m,\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m----> 2\u001b[0m     hstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Border/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/Hstrip/\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n\u001b[1;32m      3\u001b[0m     lhstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/LBorder/\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mG:/NEU/DSEM 6105/Assignments/Assignment 6/LHstrip/\u001b[39m\u001b[38;5;124m'\u001b[39m,i)\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36mhstrip\u001b[0;34m(path_in, path_out, i)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \n\u001b[1;32m      6\u001b[0m list_im \u001b[38;5;241m=\u001b[39m [path_in\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCaB.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,path_in\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCaB.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,path_in\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCaB.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m imgs    \u001b[38;5;241m=\u001b[39m [ PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m list_im ]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m min_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m( [(np\u001b[38;5;241m.\u001b[39msum(i\u001b[38;5;241m.\u001b[39msize), i\u001b[38;5;241m.\u001b[39msize ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m imgs])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "Cell \u001b[0;32mIn[6], line 7\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \n\u001b[1;32m      6\u001b[0m list_im \u001b[38;5;241m=\u001b[39m [path_in\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCaB.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,path_in\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCaB.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m,path_in\u001b[38;5;241m+\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m2\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124mCCaB.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m----> 7\u001b[0m imgs    \u001b[38;5;241m=\u001b[39m [ PIL\u001b[38;5;241m.\u001b[39mImage\u001b[38;5;241m.\u001b[39mopen(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m list_im ]\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# pick the image which is the smallest, and resize the others to match it (can be arbitrary image shape here)\u001b[39;00m\n\u001b[1;32m     10\u001b[0m min_shape \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msorted\u001b[39m( [(np\u001b[38;5;241m.\u001b[39msum(i\u001b[38;5;241m.\u001b[39msize), i\u001b[38;5;241m.\u001b[39msize ) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m imgs])[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/PIL/Image.py:3227\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3224\u001b[0m     filename \u001b[38;5;241m=\u001b[39m fp\n\u001b[1;32m   3226\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m filename:\n\u001b[0;32m-> 3227\u001b[0m     fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   3228\u001b[0m     exclusive_fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   3230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'G:/NEU/DSEM 6105/Assignments/Assignment 6/Border/0CCaB.jpg'"
     ]
    }
   ],
   "source": [
    "for i in range(0,60,3):\n",
    "    hstrip('G:/NEU/DSEM 6105/Assignments/Assignment 6/Border/','G:/NEU/DSEM 6105/Assignments/Assignment 6/Hstrip/',i)\n",
    "    lhstrip('G:/NEU/DSEM 6105/Assignments/Assignment 6/LBorder/','G:/NEU/DSEM 6105/Assignments/Assignment 6/LHstrip/',i)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b76a84bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\udayk\\AppData\\Local\\Temp\\ipykernel_21852\\3792826390.py:29: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n",
      "  imgs_comb = np.vstack( (np.asarray( i.resize(min_shape) ) for i in imgs ) )\n"
     ]
    }
   ],
   "source": [
    "for i in range(0,60,12):\n",
    "    vstrip('G:/NEU/DSEM 6105/Assignments/Assignment 6/Hstrip/','G:/NEU/DSEM 6105/Assignments/Assignment 6/Vstrip/',i)\n",
    "    lvstrip('G:/NEU/DSEM 6105/Assignments/Assignment 6/LHstrip/','G:/NEU/DSEM 6105/Assignments/Assignment 6/LVstrip/',i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c34e39",
   "metadata": {},
   "source": [
    "### Images to PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1353fe7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cpdf():\n",
    "    from PIL import Image\n",
    "    from fpdf import FPDF\n",
    "\n",
    "    pdf = FPDF()\n",
    "#    cover = Image.open(\"G:/NEU/DSEM 6105/Assignments/Assignment 6/poster.png\")\n",
    "    width, height = (595,842)\n",
    "    pdf = FPDF(unit = \"pt\", format = [width, height])\n",
    "\n",
    "    # imagelist is the list with all image filenames\n",
    "    imagelist = [\"G:/NEU/DSEM 6105/Assignments/Assignment 6/poster.png\",\n",
    "                 'G:/NEU/DSEM 6105/Assignments/Assignment 6/Vstrip/v0.jpg',\n",
    "                 'G:/NEU/DSEM 6105/Assignments/Assignment 6/Vstrip/v12.jpg',\n",
    "                'G:/NEU/DSEM 6105/Assignments/Assignment 6/Vstrip/v24.jpg',\n",
    "                'G:/NEU/DSEM 6105/Assignments/Assignment 6/Vstrip/v36.jpg',\n",
    "                'G:/NEU/DSEM 6105/Assignments/Assignment 6/Vstrip/v48.jpg']\n",
    "    for image in imagelist:\n",
    "        pdf.add_page()\n",
    "        pdf.image(image, 0, 0, width, height)\n",
    "    pdf.output(\"G:/NEU/DSEM 6105/Assignments/Assignment 6/DUAl_identity.pdf\", \"F\")\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "01f76003",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lcpdf():\n",
    "    from PIL import Image\n",
    "    from fpdf import FPDF\n",
    "\n",
    "    pdf = FPDF()\n",
    "#    cover = Image.open(\"G:/NEU/DSEM 6105/Assignments/Assignment 6/poster.png\")\n",
    "    width, height = (595,842)\n",
    "    pdf = FPDF(unit = \"pt\", format = [width, height])\n",
    "\n",
    "    # imagelist is the list with all image filenames\n",
    "    imagelist = [\"G:/NEU/DSEM 6105/Assignments/Assignment 6/poster.png\",\n",
    "                 'G:/NEU/DSEM 6105/Assignments/Assignment 6/LVstrip/lv0.jpg',\n",
    "                 'G:/NEU/DSEM 6105/Assignments/Assignment 6/LVstrip/lv12.jpg',\n",
    "                 'G:/NEU/DSEM 6105/Assignments/Assignment 6/LVstrip/lv24.jpg',\n",
    "                 'G:/NEU/DSEM 6105/Assignments/Assignment 6/LVstrip/lv36.jpg',\n",
    "                'G:/NEU/DSEM 6105/Assignments/Assignment 6/LVstrip/lv48.jpg']    \n",
    "    for image in imagelist:\n",
    "        pdf.add_page()\n",
    "        pdf.image(image, 0, 0, width, height)\n",
    "    pdf.output(\"G:/NEU/DSEM 6105/Assignments/Assignment 6/DUAl_identity_telugu.pdf\", \"F\")\n",
    "    print(\"done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7695eebd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "cpdf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "838f58b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done!\n"
     ]
    }
   ],
   "source": [
    "lcpdf()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
